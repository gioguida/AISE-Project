{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb1bc92",
   "metadata": {},
   "source": [
    "# Task 2: Resolution Invariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88606c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e219cc",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3720ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FNO import FNO1d\n",
    "# import trained model\n",
    "model_path = \"fno_1d_model.pth\"\n",
    "fno = FNO1d(modes=16, width=64)\n",
    "fno.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09d5dfa",
   "metadata": {},
   "source": [
    "## Test at different Resolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97d9562",
   "metadata": {},
   "source": [
    "### Import Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12948e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_128 = torch.from_numpy(np.load(\"data/data_test_128.npy\")).type(torch.float32)\n",
    "test_96 = torch.from_numpy(np.load(\"data/data_test_96.npy\")).type(torch.float32)\n",
    "test_64 = torch.from_numpy(np.load(\"data/data_test_64.npy\")).type(torch.float32)\n",
    "test_32 = torch.from_numpy(np.load(\"data/data_test_32.npy\")).type(torch.float32)\n",
    "\n",
    "# extract initial condition\n",
    "u0_test_128 = test_128[:, 0, :]\n",
    "u0_test_96 = test_96[:, 0, :]\n",
    "u0_test_64 = test_64[:, 0, :]\n",
    "u0_test_32 = test_32[:, 0, :]\n",
    "\n",
    "# extract solution at t=1.0\n",
    "u1_test_128 = test_128[:, -1, :]\n",
    "u1_test_96 = test_96[:, -1, :]\n",
    "u1_test_64 = test_64[:, -1, :]\n",
    "u1_test_32 = test_32[:, -1, :]\n",
    "\n",
    "# Add grid coordinates to input: shape (batch, spatial_points, 2)\n",
    "u0_test_128_grid = torch.cat([u0_test_128.unsqueeze(-1), torch.linspace(0, 1, 128).reshape(1, 128, 1).repeat(u0_test_128.shape[0], 1, 1)], dim=-1)\n",
    "u0_test_96_grid = torch.cat([u0_test_96.unsqueeze(-1), torch.linspace(0, 1, 96).reshape(1, 96, 1).repeat(u0_test_96.shape[0], 1, 1)], dim=-1)\n",
    "u0_test_64_grid = torch.cat([u0_test_64.unsqueeze(-1), torch.linspace(0, 1, 64).reshape(1, 64, 1).repeat(u0_test_64.shape[0], 1, 1)], dim=-1)\n",
    "u0_test_32_grid = torch.cat([u0_test_32.unsqueeze(-1), torch.linspace(0, 1, 32).reshape(1, 32, 1).repeat(u0_test_32.shape[0], 1, 1)], dim=-1)\n",
    "\n",
    "# Create separate DataLoaders for each resolution\n",
    "test_set_128 = DataLoader(TensorDataset(u0_test_128_grid, u1_test_128),  shuffle=False)\n",
    "test_set_96 = DataLoader(TensorDataset(u0_test_96_grid, u1_test_96),  shuffle=False)\n",
    "test_set_64 = DataLoader(TensorDataset(u0_test_64_grid, u1_test_64),  shuffle=False)\n",
    "test_set_32 = DataLoader(TensorDataset(u0_test_32_grid, u1_test_32),  shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643c807a",
   "metadata": {},
   "source": [
    "### Evaluate at different Resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc53464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loaders = [test_set_128, test_set_96, test_set_64, test_set_32]\n",
    "resolutions = [128, 96, 64, 32]\n",
    "test_relative_l2 = []\n",
    "\n",
    "fno.eval()\n",
    "with torch.no_grad():\n",
    "    for res, test_loader in zip(resolutions, test_loaders):\n",
    "        relative_l2 = 0.0\n",
    "        for input_batch, output_batch in test_loader:\n",
    "            output_pred_batch = fno(input_batch).squeeze(2)\n",
    "            loss_f = (torch.mean((output_pred_batch - output_batch) ** 2) / torch.mean(output_batch ** 2)) ** 0.5 * 100\n",
    "            relative_l2 += loss_f.item()\n",
    "        relative_l2 /= len(test_loader)\n",
    "        test_relative_l2.append(relative_l2)\n",
    "        print(f\"Resolution {res}: Relative L2 = {relative_l2:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(resolutions, test_relative_l2, marker='o')\n",
    "plt.xlabel('Resolution (Number of Spatial Points)')\n",
    "plt.ylabel('Relative L2 Error (%)') \n",
    "plt.xticks(resolutions)\n",
    "plt.title('FNO Performance Across Different Resolutions')\n",
    "# add a mark on the training resolution\n",
    "plt.axvline(x=128, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
