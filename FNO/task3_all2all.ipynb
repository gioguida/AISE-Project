{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a19e12",
   "metadata": {},
   "source": [
    "# Task 3: All2All Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8344e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a906d8",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "34b345ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FNO_bn import FNO1d_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5dfe10e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5949f60",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b1ad7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b1ad7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 1024 # number of training samples\n",
    "\n",
    "# train dataset shape: (1024, 5, 128)\n",
    "# 1024: number of trajectories\n",
    "# 5: time snapthots of the solution: t= 0, 0.25, 0.5, 0.75, 1.0\n",
    "# 128: spatial resolution of the data\n",
    "\n",
    "train_dataset = torch.from_numpy(np.load(\"data/data_train_128.npy\")).type(torch.float32)\n",
    "test_dataset = torch.from_numpy(np.load(\"data/data_test_128.npy\")).type(torch.float32)\n",
    "# add time as input feature\n",
    "time_train = torch.linspace(0, 1, train_dataset.shape[1]).reshape(1, -1, 1)\n",
    "time_test = torch.linspace(0, 1, test_dataset.shape[1]).reshape(1, -1, 1)\n",
    "train_dataset = torch.cat([train_dataset, time_train.repeat(train_dataset.shape[0], 1, 1)], dim=-1)\n",
    "test_dataset = torch.cat([test_dataset, time_test.repeat(test_dataset.shape[0], 1, 1)], dim=-1)\n",
    "\n",
    "# add grid coordinates as input feature\n",
    "grid_train = torch.linspace(0, 1, train_dataset.shape[2]).reshape(1, 1, -1)\n",
    "grid_test = torch.linspace(0, 1, test_dataset.shape[2]).reshape(1, 1, -1)\n",
    "train_dataset = torch.cat([train_dataset, grid_train.repeat(train_dataset.shape[0], train_dataset.shape[1], 1)], dim=-1)\n",
    "test_dataset = torch.cat([test_dataset, grid_test.repeat(test_dataset.shape[0], test_dataset.shape[1], 1)], dim=-1)\n",
    "\n",
    "# Move data to device\n",
    "train_dataset = train_dataset.to(device)\n",
    "test_dataset = test_dataset.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "train_loader = DataLoader(TensorDataset(train_dataset), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(test_dataset), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91cbe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDEDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 which=\"training\",\n",
    "                 training_samples = 256,\n",
    "                 resolution = 128,\n",
    "                 device='cpu'):\n",
    "\n",
    "        self.resolution = resolution\n",
    "        self.device = device\n",
    "        self.data = np.load(f\"data/data_train_{resolution}.npy\")\n",
    "\n",
    "        self.T = 5\n",
    "        # Precompute all possible (t_initial, t_final) pairs within the specified range.\n",
    "        self.time_pairs = [(i, j) for i in range(0, self.T) for j in range(i + 1, self.T)]\n",
    "        self.len_times  = len(self.time_pairs)\n",
    "\n",
    "        # Total samples available in the dataset\n",
    "        total_samples = self.data.shape[0]\n",
    "        self.n_val = 32\n",
    "        self.n_test = 32\n",
    "\n",
    "        if which == \"training\":\n",
    "            self.length = training_samples * self.len_times\n",
    "            self.start_sample = 0\n",
    "        elif which == \"validation\":\n",
    "            self.length = self.n_val * self.len_times\n",
    "            self.start_sample = total_samples - self.n_val - self.n_test\n",
    "        elif which == \"test\":\n",
    "            self.length = self.n_test * self.len_times\n",
    "            self.start_sample = total_samples - self.n_test\n",
    "\n",
    "        self.mean = 0\n",
    "        self.std  = 0.3835\n",
    "        \n",
    "        # Pre-create grid to avoid recreating it each time\n",
    "        self.grid = torch.linspace(0, 1, 128, dtype=torch.float32).reshape(128, 1).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample_idx = self.start_sample + index // self.len_times\n",
    "        time_pair_idx = index % self.len_times\n",
    "        t_inp, t_out = self.time_pairs[time_pair_idx]\n",
    "        time = torch.tensor((t_out - t_inp)/5. + float(np.random.rand(1)[0]/10**6), dtype=torch.float32, device=self.device)\n",
    "\n",
    "        inputs = torch.from_numpy(self.data[sample_idx, t_inp]).type(torch.float32).reshape(128, 1).to(self.device)\n",
    "        inputs = (inputs - self.mean)/self.std #Normalize\n",
    "        \n",
    "        # Add grid coordinates (already on correct device and dtype)\n",
    "        inputs = torch.cat((inputs, self.grid), dim=-1)  # (128, 2)\n",
    "\n",
    "        outputs = torch.from_numpy(self.data[sample_idx, t_out]).type(torch.float32).reshape(128).to(self.device)\n",
    "        outputs = (outputs - self.mean)/self.std #Normalize\n",
    "\n",
    "        return time, inputs, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a2f0b0",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987425ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 1024 # Number of TRAJECTORIES for training\n",
    "batch_size = 20\n",
    "\n",
    "training_set = DataLoader(PDEDataset(\"training\", n_train, device=device), batch_size=batch_size, shuffle=True)\n",
    "testing_set = DataLoader(PDEDataset(\"validation\", device=device), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "step_size = 2\n",
    "gamma = 0.5\n",
    "\n",
    "modes = 16\n",
    "width = 64\n",
    "fno = FNO1d_bn(modes, width).to(device)  # model\n",
    "\n",
    "optimizer = torch.optim.Adam(fno.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7333a2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m test_relative_l2 = \u001b[32m0.0\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, (time_batch, input_batch, output_batch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(testing_set):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     output_pred_batch = \u001b[43mfno\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_batch\u001b[49m\u001b[43m)\u001b[49m.squeeze(-\u001b[32m1\u001b[39m)\n\u001b[32m     23\u001b[39m     loss_f = (torch.mean((\u001b[38;5;28mabs\u001b[39m(output_pred_batch - output_batch))) / torch.mean(\u001b[38;5;28mabs\u001b[39m(output_batch))) * \u001b[32m100\u001b[39m\n\u001b[32m     24\u001b[39m     test_relative_l2 += loss_f.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giogu\\Desktop\\ETH\\Courses\\2025_fall\\AISE\\project\\FNO\\FNO_bn.py:129\u001b[39m, in \u001b[36mFNO1d_bn.forward\u001b[39m\u001b[34m(self, x, time)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# Concatenate: (u0(x), grid, time)\u001b[39;00m\n\u001b[32m    127\u001b[39m x = torch.cat([x, time_expanded], dim=-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (batch, spatial_points, 3)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlinear_p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m x = x.permute(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# x = F.pad(x, [0, self.padding])  # pad the domain if input is non-periodic\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "source": [
    "l = nn.L1Loss()\n",
    "freq_print = 1\n",
    "for epoch in range(epochs):\n",
    "    fno.train()\n",
    "    train_mse = 0.0\n",
    "    for step, (time_batch, input_batch, output_batch) in enumerate(training_set):\n",
    "        optimizer.zero_grad()\n",
    "        output_pred_batch = fno(input_batch, time_batch).squeeze(-1)\n",
    "        loss_f = l(output_pred_batch, output_batch)\n",
    "        loss_f.backward()\n",
    "        optimizer.step()\n",
    "        train_mse += loss_f.item()\n",
    "    train_mse /= len(training_set)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fno.eval()\n",
    "        test_relative_l2 = 0.0\n",
    "        for step, (time_batch, input_batch, output_batch) in enumerate(testing_set):\n",
    "            output_pred_batch = fno(input_batch, time_batch).squeeze(-1)\n",
    "            loss_f = (torch.mean((abs(output_pred_batch - output_batch))) / torch.mean(abs(output_batch))) * 100\n",
    "            test_relative_l2 += loss_f.item()\n",
    "        test_relative_l2 /= len(testing_set)\n",
    "\n",
    "    if epoch % freq_print == 0: print(\"######### Epoch:\", epoch, \" ######### Train Loss:\", train_mse, \" ######### Relative L1 Test Norm:\", test_relative_l2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
